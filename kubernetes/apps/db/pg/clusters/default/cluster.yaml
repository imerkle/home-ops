---
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: pg-default
  # annotations:
  #   cnpg.io/skipEmptyWalArchiveCheck: "enabled"
spec:
  # inheritedMetadata:
  #   annotations:
  #     vault.security.banzaicloud.io/vault-addr: "http://vault.vault:8200"
  env:
    - name: AWS_REQUEST_CHECKSUM_CALCULATION
      value: "when_required"
    - name: AWS_RESPONSE_CHECKSUM_VALIDATION
      value: "when_required"
  instances: 1
  imageName: ghcr.io/cloudnative-pg/postgresql:15.2-11
  primaryUpdateStrategy: unsupervised # let k8s handle upgrades
  primaryUpdateMethod: restart # prefer downtime of image download from registry instead of switching primary instance (promote a standby instance to primary) when current primary pod is updated
  storage:
    size: 25Gi
    storageClass: "${STORE1}"
  walStorage:
    storageClass: "${STORE1}"
    size: 35Gi
  superuserSecret:
    name: pg-default-superuser
  enableSuperuserAccess: true
  postgresql:
    parameters:
      max_connections: "600"
      shared_buffers: 512MB # amount of RAM to use for data caching, https://postgresqlco.nf/doc/en/param/shared_buffers/
  monitoring:
    enablePodMonitor: true
  backup:
    target: "primary"
    retentionPolicy: 30d
    volumeSnapshot:
       className: ${VSNAP1}
    barmanObjectStore:
      serverName: "${PG_S3_FOLDER_CURR}"
      wal:
        compression: bzip2
        maxParallel: 8
      destinationPath: s3://pg-default
      # endpointURL: http://minio.minio:9000
      # endpointURL: ${S3_ENDPOINT}
      endpointURL: "http://rook-ceph-rgw-ceph-objectstore.rook-ceph.svc:80"
      # serverName: pg-default-v1
      s3Credentials:
        accessKeyId:
          name: &secret pg-default-s3
          key: AWS_ACCESS_KEY_ID_CEPH
        secretAccessKey:
          name: *secret
          key: AWS_SECRET_ACCESS_KEY_CEPH
      # Your internal Ceph RGW Service URL (e.g., inside the cluster)
#  # RECOVERY
  bootstrap:
    recovery:
      source: &previous-cluster pg-default-restore
    # Note: externalClusters is needed when recovering from an existing cnpg cluster
  externalClusters:
    - name: *previous-cluster
      barmanObjectStore:
        serverName: "${PG_S3_FOLDER_PREV}"
        wal:
          compression: bzip2
          maxParallel: 8
        destinationPath: s3://pg-default
        endpointURL: "https://s3.us-west-002.backblazeb2.com"
        s3Credentials:
          accessKeyId:
            name: &secret pg-default-s3
            key: AWS_ACCESS_KEY_ID
          secretAccessKey:
            name: *secret
            key: AWS_SECRET_ACCESS_KEY
